{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> APIs and Modules for Tensorflow </center> \n",
    "There are multiple APIs available to support different IOPS and Deep learning.\n",
    "1. Keras - High level API for deep learning.\n",
    "2. Data\n",
    "3. Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out multiple lines in output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import modules\n",
    "import os\n",
    "import numpy as np \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.__version__\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train.shape\n",
    "x_test.shape\n",
    "\n",
    "# Normalize dataset\n",
    "x_train, x_test = x_train/255.0, x_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Keras API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.2119 - accuracy: 0.9356\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0888 - accuracy: 0.9728\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.0613 - accuracy: 0.9808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb32354748>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  401920    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  65664     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  1290      \n",
      "=================================================================\n",
      "Total params: 468,874\n",
      "Trainable params: 468,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 0s 48us/sample - loss: 0.0801 - accuracy: 0.9753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08005141494031413, 0.9753]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and evaluate a sequential model in Keras\n",
    "epochs=3\n",
    "batch_size=32\n",
    "steps_per_epoch = len(x_train)//batch_size\n",
    "\n",
    "def build_estimator():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(512, activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "    model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_estimator()\n",
    "model.fit(x_train, y_train, \n",
    "          batch_size=batch_size,\n",
    "         epochs=epochs)\n",
    "model.summary()\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subclassing Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0513 13:29:31.057957 4559877568 hdf5_format.py:266] Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "# Save and load keras models\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('./output/02/mnist_model.h5')\n",
    "model.save_weights('./output/02/mnist_model_weights.h5')\n",
    "new_model = load_model('./output/02/mnist_model.h5')\n",
    "new_model_weights = new_model.load_weights('./output/02/mnist_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMnistModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyMnistModel, self).__init__()\n",
    "        \n",
    "        # Define layers\n",
    "        inputs = tf.keras.Input((28,28))\n",
    "        self.x0 = tf.keras.layers.Flatten()\n",
    "        self.x1 = tf.keras.layers.Dense(512, activation=tf.nn.relu, name='d1')\n",
    "        self.x2 = tf.keras.layers.Dropout(0.2)\n",
    "        self.predictions = tf.layers.Dense(10, activation=tf.nn.softmax, name='d2')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.x0(inputs)\n",
    "        x = self.x1(x)\n",
    "        x = self.x2(x)\n",
    "        return self.predictions(x)\n",
    "\n",
    "sub_model = MyMnistModel()\n",
    "sub_model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "sub_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n",
    "sub_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data API - Building data pipelines\n",
    "\n",
    "To build data pipelines, we need to read data from different source and make iterable dataset function to feed into transformation and analytical pipelines.\n",
    "- Build from numpy array\n",
    "- From CSV\n",
    "- From TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb50aec470>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb33e8f208>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb3576c5f8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert numpy arrays into dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(10).shuffle(10000)\n",
    "\n",
    "# Map image functin to data `tf.image`\n",
    "train_dataset = train_dataset.map(lambda x, y: (tf.image.random_flip_left_right(x), y))\n",
    "iterator = tf.compat.v1.data.make_one_shot_iterator(train_dataset)\n",
    "\n",
    "for i, item in enumerate(train_dataset):\n",
    "    plt.imshow(tf.squeeze(iterator.get_next()[0]).numpy())\n",
    "    plt.show()\n",
    "    \n",
    "    if i==2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from csv file\n",
    "file = './data/Data.csv'\n",
    "default_value = ['0','missing',0.0,0.0,'missing'] # replace Null with defaults\n",
    "dataset = tf.data.experimental.CsvDataset(file, \n",
    "                                          record_defaults=default_value,\n",
    "                                         header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=3307, shape=(4,), dtype=string, numpy=array([b'5', b'6', b'7', b'8'], dtype=object)>,\n",
       " <tf.Tensor: id=3308, shape=(4,), dtype=string, numpy=array([b'Germany', b'France', b'Spain', b'France'], dtype=object)>,\n",
       " <tf.Tensor: id=3309, shape=(4,), dtype=float32, numpy=array([40., 35.,  0., 48.], dtype=float32)>,\n",
       " <tf.Tensor: id=3310, shape=(4,), dtype=float32, numpy=array([    0., 58000., 52000., 79000.], dtype=float32)>,\n",
       " <tf.Tensor: id=3311, shape=(4,), dtype=string, numpy=array([b'Yes', b'Yes', b'No', b'Yes'], dtype=object)>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=3322, shape=(4,), dtype=string, numpy=array([b'1', b'2', b'3', b'4'], dtype=object)>,\n",
       " <tf.Tensor: id=3323, shape=(4,), dtype=string, numpy=array([b'France', b'Spain', b'Germany', b'Spain'], dtype=object)>,\n",
       " <tf.Tensor: id=3324, shape=(4,), dtype=float32, numpy=array([44., 27., 30., 38.], dtype=float32)>,\n",
       " <tf.Tensor: id=3325, shape=(4,), dtype=float32, numpy=array([72000., 48000., 54000., 61000.], dtype=float32)>,\n",
       " <tf.Tensor: id=3326, shape=(4,), dtype=string, numpy=array([b'No', b'Yes', b'No', b'No'], dtype=object)>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch add another dimension and group values as defined number \n",
    "# Shuffle data based on buffer size\n",
    "dataset = dataset.batch(4, drop_remainder=True).shuffle(15)\n",
    "iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)\n",
    "\n",
    "for item in dataset:\n",
    "    iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write array to TF Record and read from it\n",
    "data = {\n",
    "    'ID': 1234,\n",
    "'Name': ['Pankaj','Sharma'],\n",
    "'Scores': [45.6, 97.2]\n",
    "}\n",
    "\n",
    "\n",
    "def write_to_tfrecord(fname, data):\n",
    "    writer = tf.io.TFRecordWriter(fname)\n",
    "    feature = {}\n",
    "    feature['ID'] = tf.train.Feature(int64_list=tf.train.Int64List(value=[data['ID']]))\n",
    "    feature['Name'] = tf.train.Feature(bytes_list=tf.train.BytesList(value=[n.encode('utf-8') for n in data['Name']]))\n",
    "    feature['Scores'] = tf.train.Feature(float_list=tf.train.FloatList(value=data['Scores']))\n",
    "    \n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    serialized = example.SerializeToString()\n",
    "    writer.write(serialized)\n",
    "    writer.close()\n",
    "\n",
    "write_to_tfrecord('./data/test.tfrecord', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'\\nB\\n\\x1a\\n\\x04Name\\x12\\x12\\n\\x10\\n\\x06Pankaj\\n\\x06Sharma\\n\\x0c\\n\\x02ID\\x12\\x06\\x1a\\x04\\n\\x02\\xd2\\t\\n\\x16\\n\\x06Scores\\x12\\x0c\\x12\\n\\n\\x08ff6Bff\\xc2B', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# Read from tf record file\n",
    "dataset = tf.data.TFRecordDataset('./data/test.tfrecord')\n",
    "\n",
    "# Data is in serialized format - decode \n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: id=3794, shape=(), dtype=int64, numpy=1234>, <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0xb5adc0780>, <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0xb5ae25860>)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.TFRecordDataset('./data/test.tfrecord')\n",
    "\n",
    "def parse_function(example_proto):\n",
    "    keys_to_features = {'ID':tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "                       'Name': tf.io.VarLenFeature(dtype=tf.string),\n",
    "                        'Scores': tf.io.VarLenFeature(dtype=tf.float32)\n",
    "                       }\n",
    "    parsed_features = tf.io.parse_single_example(serialized=example_proto, features=keys_to_features)\n",
    "    return parsed_features['ID'], parsed_features['Name'], parsed_features['Scores']\n",
    "\n",
    "dataset = dataset.map(parse_function)\n",
    "iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)\n",
    "# array is retrieved as one item\n",
    "item = iterator.get_next()\n",
    "print(item)\n",
    "#print(item.numpy())\n",
    "#print(item[2].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:  1234\n",
      "Name: Pankaj , Sharma\n",
      "Scores:  [45.6 97.2]\n"
     ]
    }
   ],
   "source": [
    "print(\"ID: \",item[0].numpy())\n",
    "name = item[1].values.numpy()\n",
    "name1= name[0].decode()\n",
    "name2 = name[1].decode('utf8')\n",
    "print(\"Name:\",name1,\",\",name2)\n",
    "print(\"Scores: \",item[2].values.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a function to ingest data in pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(filename, mode, batch_size = 512):\n",
    "    def _input_fn():\n",
    "        def decode_csv(value_column):\n",
    "            columns = tf.decode_csv(records = value_column, record_defaults = DEFAULTS)\n",
    "            features = dict(zip(CSV_COLUMNS, columns))          \n",
    "            label = features.pop(LABEL_COLUMN)         \n",
    "            return features, label\n",
    "\n",
    "        # Create list of files that match pattern\n",
    "        file_list = tf.gfile.Glob(filename = filename)\n",
    "\n",
    "        # Create dataset from file list\n",
    "        dataset = tf.data.TextLineDataset(filenames = file_list).map(map_func = decode_csv)\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            num_epochs = None # indefinitely\n",
    "            dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "        else:\n",
    "            num_epochs = 1 # end-of-input after this\n",
    "\n",
    "        dataset = dataset.repeat(count = num_epochs).batch(batch_size = batch_size)\n",
    "        return dataset.make_one_shot_iterator().get_next()\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function from model function snippet\n",
    "\n",
    "args = {'train_data_paths': 'path-for-train-files',\n",
    "       'batch_size': 512,\n",
    "       'train_steps': 100000,\n",
    "       'eval_data_paths': 'path-for-eval-files',\n",
    "       'start_delay_secs': 60,\n",
    "       'throttle_secs': 100}\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn = read_dataset(filename = args['train_data_paths'], \n",
    "                            mode = tf.estimator.ModeKeys.TRAIN, \n",
    "                            batch_size = args['batch_size']),\n",
    "    max_steps = args['train_steps'])\n",
    "\n",
    "#exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn = read_dataset(filename = args['eval_data_paths'], \n",
    "                            mode = tf.estimator.ModeKeys.EVAL, \n",
    "                            batch_size = args['batch_size']),\n",
    "    steps = None,\n",
    "    start_delay_secs = args['start_delay_secs'],\n",
    "    throttle_secs = args['throttle_secs'],\n",
    "    #exporters = exporter\n",
    ")\n",
    "\n",
    "#tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Estimator API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
